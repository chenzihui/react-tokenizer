{
  "name": "react-tokenizer",
  "description": "A React.js component for tokenizing user input",
  "version": "0.1.0",
  "author": "Chen Zihui <hello@chenzihui.com>",
  "main": "lib/Tokenizer.js",
  "repository": {
    "type": "git",
    "url": "https://github.com/chenzihui/react-tokenizer"
  },
  "homepage": "https://github.com/chenzihui/react-tokenizer",
  "bugs": "https://github.com/chenzihui/react-tokenizer/issues",
  "scripts": {
    "test": "jest"
  },
  "peerDependencies": {
    "react": "^0.13.3"
  },
  "devDependencies": {
    "babel-jest": "^4.0.0",
    "babelify": "^5.0.4",
    "browserify": "^9.0.3",
    "del": "^1.1.1",
    "gulp": "^3.8.11",
    "gulp-babel": "^5.2.1",
    "gulp-plumber": "^0.6.6",
    "gulp-uglify": "^1.1.0",
    "gulp-util": "^3.0.4",
    "gulp-webserver": "^0.9.0",
    "jest-cli": "^0.5.10",
    "react-tools": "^0.13.3",
    "vinyl-source-stream": "^1.0.0",
    "watchify": "^2.4.0"
  },
  "jest": {
    "scriptPreprocessor": "<rootDir>/node_modules/babel-jest",
    "unmockedModulePathPatterns": [
      "<rootDir>/node_modules/react"
    ],
    "testFileExtensions": [
      "es6",
      "js"
    ],
    "moduleFileExtensions": [
      "js",
      "json",
      "es6"
    ]
  },
  "license": "MIT",
  "tags": [
    "react",
    "tokenizer"
  ],
  "keywords": [
    "react",
    "react-component",
    "tokenizer",
    "tokens",
    "input",
    "textarea"
  ],
  "dependencies": {
    "react-input-autosize": "^0.5.3"
  }
}
